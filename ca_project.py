# -*- coding: utf-8 -*-
"""CA project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1poJ9tTUTa1lZLZQd8lbA6Ts7BiGPXz50

## Project
"""

import numpy as np
import pandas as pd
import nltk

np.random.seed(5)

movies_df = pd.read_csv("movies.csv")

print("Number of movies loaded: %s " % (len(movies_df)))

movies_df

movies_df["plot"] = movies_df["wiki_plot"].astype(str) + "\n" + \
                 movies_df["imdb_plot"].astype(str)

movies_df.head()

nltk.download('punkt')

sent_tokenized = [sent for sent in nltk.sent_tokenize("""
                        Today (May 19, 2016) is his only daughter's wedding.
                        Vito Corleone is the Godfather.
                        """)]

words_tokenized = [word for word in nltk.word_tokenize(sent_tokenized[0])]

import re

filtered = [word for word in words_tokenized if re.search('[a-zA-Z]', word)]

filtered

from nltk.stem.snowball import SnowballStemmer

stemmer = SnowballStemmer("english")

print("Without stemming: ", filtered)

stemmed_words = [stemmer.stem(word) for word in filtered]

print("After stemming:   ", stemmed_words)

def tokenize_and_stem(text):

    tokens = [result for t in nltk.sent_tokenize(text)
                          for result in nltk.word_tokenize(t)]

    filtered_tokens = [token for token in tokens if re.search('[a-zA-Z]', token)]

    stems = [stemmer.stem(t) for t in filtered_tokens]
    return stems

words_stemmed = tokenize_and_stem("Today (May 19, 2016) is his only daughter's wedding.")
print(words_stemmed)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,
                                 min_df=0.2, stop_words='english',
                                 use_idf=True, tokenizer=tokenize_and_stem,
                                 ngram_range=(1,3))

tfidf_matrix = tfidf_vectorizer.fit_transform([x for x in movies_df["plot"]])

print(tfidf_matrix.shape)

from sklearn.cluster import KMeans

km = KMeans(n_clusters=5)

km.fit(tfidf_matrix)

clusters = km.labels_.tolist()

movies_df["cluster"] = clusters

movies_df['cluster'].value_counts()

from sklearn.metrics.pairwise import cosine_similarity

similarity_distance = 1 - cosine_similarity(tfidf_matrix)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# %matplotlib inline

from scipy.cluster.hierarchy import linkage, dendrogram

mergings = linkage(similarity_distance, method='complete')

dendrogram_ = dendrogram(mergings,
               labels=[x for x in movies_df["title"]],
               leaf_rotation=90,
               leaf_font_size=16,
)

fig = plt.gcf()
_ = [lbl.set_color('r') for lbl in plt.gca().get_xmajorticklabels()]
fig.set_size_inches(108, 21)

plt.show()

# Import PCA for dimensionality reduction
from sklearn.decomposition import PCA

# Reduce dimensions of TF-IDF matrix to 2 using PCA
pca = PCA(n_components=2)
tfidf_matrix_pca = pca.fit_transform(tfidf_matrix.toarray())

# Create a DataFrame for the reduced TF-IDF matrix
tfidf_df = pd.DataFrame(tfidf_matrix_pca, columns=['PC1', 'PC2'])

# Add cluster labels to the DataFrame
tfidf_df['cluster'] = clusters

# Plot the scatter plot
plt.figure(figsize=(10, 6))

# Iterate over each cluster and plot its data points
for cluster in range(5):
    cluster_points = tfidf_df[tfidf_df['cluster'] == cluster]
    plt.scatter(cluster_points['PC1'], cluster_points['PC2'], label=f'Cluster {cluster}', alpha=0.7)

plt.title('KMeans Clustering of Movie Plots')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.grid(True)
plt.show()

# Get centroids of each cluster
centroids = km.cluster_centers_

# Transform centroids to 2D using PCA
centroids_pca = pca.transform(centroids)

# Plot the scatter plot
plt.figure(figsize=(10, 6))

# Iterate over each cluster and plot its data points
for cluster in range(5):
    cluster_points = tfidf_df[tfidf_df['cluster'] == cluster]
    plt.scatter(cluster_points['PC1'], cluster_points['PC2'], label=f'Cluster {cluster}', alpha=0.7)

# Plot centroids
plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], marker='x', color='red', s=200, label='Centroids')

plt.title('KMeans Clustering of Movie Plots with Centroids')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.grid(True)
plt.show()

def predict_similar_movies(previous_movie, n_recommendations=5):
    # Find the cluster of the previous movie
    previous_movie_cluster = movies_df.loc[movies_df['title'] == previous_movie, 'cluster'].values[0]

    # Filter movies in the same cluster as the previous movie
    similar_movies = movies_df[movies_df['cluster'] == previous_movie_cluster]

    # Exclude the previous movie itself
    similar_movies = similar_movies[similar_movies['title'] != previous_movie]

    # Sort similar movies based on some criteria (e.g., popularity, rating) and select top recommendations
    similar_movies = similar_movies.head(n_recommendations)

    return similar_movies['title'].tolist()

# Example: Predict similar movies after watching "The Godfather"
previous_movie = "The King's Speech"
similar_movies = predict_similar_movies(previous_movie)
print("Similar movies to", previous_movie, ":", similar_movies)